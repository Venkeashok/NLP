{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\yuvateja\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: regex in c:\\users\\yuvateja\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\yuvateja\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\yuvateja\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yuvateja\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the dataset (5 points)\n",
    "a. Tip: As the dataset is large, use fewer rows. Check what is working well on your machine and \n",
    "decide accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('blogtext.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "gender       0\n",
       "age          0\n",
       "topic        0\n",
       "sign         0\n",
       "date         0\n",
       "text      3000\n",
       "labels       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocess rows of the “text” column (7.5 points)\n",
    "a. Remove unwanted characters\n",
    "b. Convert text to lowercase\n",
    "c. Remove unwanted spaces\n",
    "d. Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text'] = df2['text'].str.replace('[^A-Za-z]',' ')\n",
    "df2['text'] = df2['text'].str.lower()\n",
    "df2['text'] = df2['text'].str.strip()\n",
    "df2['text'] = df2['text'].str.split()  \n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "df2.text = df2.text.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. As we want to make this into a multi-label classification problem, you are required to merge all the label \n",
    "columns together, so that we have all the labels together for a particular sentence (7.5 points)\n",
    "a. Label columns to merge: “gender”, “age”, “topic”, “sign”\n",
    "b. After completing the previous step, there should be only two columns in your data frame i.e. “text” \n",
    "and “labels” as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['age'] = df2['age'].astype(str)\n",
    "df2['labels']=df2[['gender','age','topic','sign']].apply(lambda x:','.join(x), axis = 1) \n",
    "merged_df=df2.drop(labels =['date','gender', 'age','topic','sign','id'], axis = 1)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Separate features and labels, and split the data into training and testing (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df['text']\n",
    "merged_df['labels'] = merged_df['labels'].str.lower()= mergedg_df['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state = 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Vectorize the features (5 points)\n",
    "a. Create a Bag of Words using count vectorizer\n",
    "i. Use ngram_range=(1, 2)\n",
    "ii. Vectorize training and testing features\n",
    "b. Print the term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 2,ngram_range = (1,2),stop_words = \"english\")\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "vectorizer_labels = CountVectorizer(min_df = 1,ngram_range = (1,1),stop_words = \"english\")\n",
    "labels_vector = vectorizer_labels.fit_transform(labels)\n",
    "label_classes=[]\n",
    "for  key in vectorizer_labels.vocabulary_.keys():\n",
    "    label_classes.append(key)\n",
    "MLB = MultiLabelBinarizer(classes = label_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Transform the labels - (7.5 points)\n",
    "As we have noticed before, in this task each example can have multiple tags. To deal with such kind of \n",
    "prediction, we need to transform labels in a binary form and the prediction will be a mask of 0s and 1s. \n",
    "For this purpose, it is convenient to use MultiLabelBinarizer from sklearn\n",
    "a. Convert your train and test labels using MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[\"\".join(re.findall(\"\\w\",f)) for f in lst] for lst in [s.split(\",\") for s in y]]\n",
    "labels_trans = mlb.fit(labels) \n",
    "y_train = [[\"\".join(re.findall(\"\\w\",f)) for f in lst] for lst in [s.split(\",\") for s in y_train]]\n",
    "y_train = mlb.transform(y_train)\n",
    "Y_test = [[\"\".join(re.findall(\"\\w\",f)) for f in lst] for lst in [s.split(\",\") for s in y_test]]\n",
    "y_test_trans = mlb.transform(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Choose a classifier - (5 points)\n",
    "In this task, we suggest using the One-vs-Rest approach, which is implemented in OneVsRestClassifier\n",
    "class. In this approach k classifiers (= number of tags) are trained. As a basic classifier, use \n",
    "LogisticRegression. It is one of the simplest methods, but often it performs good enough in text \n",
    "classification tasks. It might take some time because the number of classifiers to train is large.\n",
    "a. Use a linear classifier of your choice, wrap it up in OneVsRestClassifier to train it on every label\n",
    "b. As One-vs-Rest approach might not have been discussed in the sessions, we are providing you \n",
    "with the code for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver = 'lbfgs',max_iter = 1000) \n",
    "clf = OneVsRestClassifier(clf)\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy:\",clf.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Fit the classifier, make predictions and get the accuracy (5 points)\n",
    "a. Print the following\n",
    "i. Accuracy score\n",
    "ii. F1 score\n",
    "iii. Average precision score\n",
    "iv. Average recall score\n",
    "v. Tip: Make sure you are familiar with all of them. How would you expect the things to \n",
    "work for the multi-label scenario? Read about micro/macro/weighted averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test Accuracy:\" + str(accuracy_score(y_test,y_pred)))\n",
    "print(\"F1: \" + str(f1_score(y_test,y_pred)))\n",
    "print(\"F1_macro: \" + str(f1_score(y_test,y_pred)))\n",
    "print(\"Precision: \" + str(precision_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Print true label and predicted label for any five examples (7.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Predicted :\",y_pred[24])\n",
    "print(\" Actual :\",y_test[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Predicted :\",y_pred[55])\n",
    "print(\" Actual :\",y_test[55])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
